{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import *\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "import re \n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=open(\"./a1_data/a1_d3.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=file1.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=[x.strip() for x in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[]\n",
    "text=[]\n",
    "for c in content:\n",
    "    classes.append(int(c[-1]))\n",
    "    a=c[0:len(c)-2]\n",
    "    text.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2=[]\n",
    "for t in text:\n",
    "    s=''\n",
    "    for c in t:\n",
    "        if(c in string.punctuation or c.isdigit()):\n",
    "            s+=' '\n",
    "            continue\n",
    "        s+=c\n",
    "    text2.append(\" \".join(s.split()).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the only thing that disappoint me is the infra red port irda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=[]\n",
    "t=[]\n",
    "for i in range(0,5):\n",
    "    d1=text2[i*200:(i+1)*200]\n",
    "    t1=classes[i*200:(i+1)*200]\n",
    "    d.append(d1)\n",
    "    t.append(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you can not answer calls with the unit never worked once'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[4][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f_score=[]\n",
    "for i in range(0,5):\n",
    "    sc=[]\n",
    "    x_train=[]\n",
    "    t_train=[]\n",
    "    x_test=[]\n",
    "    t_test=[]\n",
    "    for j in range(0,5):\n",
    "        if(j!=i):\n",
    "            for a in d[j]:\n",
    "                x_train.append(a)\n",
    "            for a in t[j]:\n",
    "                t_train.append(a)\n",
    "        if(j==i):\n",
    "            for a in d[j]:\n",
    "                x_test.append(a)\n",
    "            for a in t[j]:\n",
    "                t_test.append(a)\n",
    "    words_0={}\n",
    "    words_1={}\n",
    "    count0=t_train.count(0)\n",
    "    count1=t_train.count(1)\n",
    "    c0=0\n",
    "    c1=0\n",
    "    for u in range(0,len(x_train)):\n",
    "        res=x_train[u].split()\n",
    "        for c in res:\n",
    "            if(t_train[u]==0):\n",
    "                c0+=1\n",
    "                if c not in words_0:\n",
    "                    words_0[c]=1\n",
    "                else:\n",
    "                    words_0[c]+=1\n",
    "            if(t_train[u]==1):\n",
    "                c1+=1\n",
    "                if c not in words_1:\n",
    "                    words_1[c]=1\n",
    "                else:\n",
    "                    words_1[c]+=1\n",
    "    a=len(words_0)\n",
    "#     print(words_1)\n",
    "    for key,value in words_0.items():\n",
    "        if key not in words_1.items():\n",
    "            a+=1\n",
    "    prob_words_0={}\n",
    "    prob_words_1={}\n",
    "    for key,value in words_0.items():\n",
    "        if key not in prob_words_0:\n",
    "            prob_words_0[key]=(words_0[key]+1)/(c0+a)\n",
    "    for key,value in words_1.items():\n",
    "        if key not in prob_words_1:\n",
    "            prob_words_1[key]=(words_1[key]+1)/(c1+a)\n",
    "    m=0\n",
    "    for u in range(0,len(x_test)):\n",
    "        p0=1\n",
    "        p1=1\n",
    "        ans=-1\n",
    "        res=x_test[u].split()\n",
    "        for c in res:\n",
    "            if c in prob_words_0:\n",
    "                p0*=prob_words_0[c]\n",
    "            else:\n",
    "                p0*=(1/(c0+a))\n",
    "            if c in prob_words_1:\n",
    "                p1*=prob_words_1[c]\n",
    "            else:\n",
    "                p1*=(1/(c1+a))\n",
    "        p0=p0*((count0/(count0+count1)))\n",
    "        p1=p1*((count1/(count0+count1)))\n",
    "        if(p0>p1):\n",
    "            sc.append(0)\n",
    "        else:\n",
    "            sc.append(1)\n",
    "#     print(x_test)\n",
    "    tn=0\n",
    "    tp=0\n",
    "    fn=0\n",
    "    fp=0\n",
    "    for u in range(0,len(t_test)):\n",
    "        if(sc[u]==t_test[u]):\n",
    "            if(t_test[u]==1):\n",
    "                tp+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "        else:\n",
    "            if(t_test[u]==1):\n",
    "                fn+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "    pr=tp/(tp+fp)\n",
    "    re=tp/(tp+fn)\n",
    "#     print(re)\n",
    "    accuracy.append((tp+tn)/(tp+tn+fp+fn))\n",
    "    precision.append(pr)\n",
    "    recall.append(re)\n",
    "    f_score.append(2*pr*re/(pr+re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.835, 0.83, 0.775, 0.79, 0.805]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=np.mean(accuracy)\n",
    "std=np.std(accuracy)\n",
    "m1=np.mean(precision)\n",
    "std1=np.std(precision)\n",
    "m2=np.mean(recall)\n",
    "std2=np.std(recall)\n",
    "m3=np.mean(f_score)\n",
    "std3=np.std(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.807 +/- 0.022934689882359402\n",
      "Precision:  0.7903353021910015 +/- 0.027605183658560743\n",
      "Recall:  0.8325498488446328 +/- 0.04027951436872136\n",
      "F_Score:  0.8105623007499124 +/- 0.029507609290674933\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",m,\"+/-\",std)\n",
    "print(\"Precision: \",m1,\"+/-\",std1)\n",
    "print(\"Recall: \",m2,\"+/-\",std2)\n",
    "print(\"F_Score: \",m3,\"+/-\",std3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
